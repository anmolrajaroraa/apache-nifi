1. Decompress and untar
	bin directory -> ./nifi.sh <command>
-start -> start NiFi in the background
-stop -> stop NiFi that's running in background
-status -> provides you current status of nifi
-run -> run NiFi in the cmd directly
-service -> install NiFi as a service
	service nifi start
	service nifi stop
	service nifi status

1. Decompress
	bin directory -> double-click run-nifi.bat

These directories are created :-
1. content_repository
2. database_repository
3. flowfile_repository
4. provenance_repository
5. work directory
6. logs directory

Go to browser -> localhost:8080/nifi

Apache NiFi was built to manage data flow
-systems fail
-data access exceeds capacity to consume
-noise today can become resource tomorrow
-boundary conditions
-compliance and security
-continuous improvement occurs in production

Core components:- (FBP programming)
1. FlowFile (information packet)
2. FlowFile Processor
3. FlowFile Controller (Scheduler)
4. Process Group

Before zero-master clustering
Master-slave relationship. Master is single point of failure. If master dies, slaves still keep on working but we cannot manage them or make any changes in the dataflow.

Zero-master clustering
No master is there. Cluster coordinator was introduced. Primary node and cluster coordinator are selected by zookeeper. No single point of failure.


Cluster is a group of nodes performing same tasks but on different data sets.

Why cluster?
1. To group all the nodes to increase processing capability
2. Clustering allows NiFi Administrators or DFM(DataFlow Managers) to have a single interface through which they can make dataflow changes and monitor the dataflow and status of all the nodes

Node - Nodes do the actual processing. Node is just a machine comprising of 3 simple resources - CPU power, RAM, disk space

ZooKeeper - electing Primary Node, electing Cluster Coordinator and acting as a middleware between different nodes so that they can communicate to each other

Cluster Coordinator - managing the nodes, providing up-to-date flow to newly-joining node, replicating the changes to all the nodes in the cluster

Primary Node - Every cluster has one Primary Node. On this node, we can run 'Isolated Processors'. ZooKeeper automatically selects a node to become Primary Node.

Isolated Processors - These processors run in isloated environment on the Primary Node. Eg :- GetSFTP Processor

Heartbeats - Nodes emit health and status check after every 5 seconds to the cluster coordinator to let it know that they are working in sync and are alive

Communication within the cluster

Managing the nodes

Steps to decommission a node:-
1. Disconnect the node
2. Offload the node
3. Delete the node
4. Restart nifi service 

NiFi Toolkit
- nifi get-node
- nifi get-nodes
- nifi connect-node
- nifi disconnect-node
- nifi offload-node
- nifi delete-node

Flow election
When a cluster first starts up, voting is done for the copy of flows submitted by nodes to the cluster coordinator. If two flows match. a vote is casted. And the flow having majority of votes is selected as cluster's flow. All the nodes not having this flow are disconnected and are provided with a copy of up-to-date flow to become compatible to cluster's flow.
If no flow gets majority, cluster coordinator selects the correct flow and rest of the procedure is same.
nifi.cluster.flow.max.candidtates = <number>
nifi.cluster.flow.max.wait.time = <time>

Steps to setup a cluster
nifi.cluster.is.node = true
nifi.web.http.port = <port-number> (should be different for all nodes)
nifi.zookeeper.connect.string = localhost:2181
nifi.zookeeper.embedded.start = true (only on a single node)
nifi.cluster.load.balance.port=6342 (should be diff. for all nodes)
In zookeeper.properties -> server.1=localhost:2888:3888

DataFlow Manager - A NiFi user who has permissions to add, remove and modify components of a NiFi dataflow.

FlowFile - FlowFile represents a single piece of data. FlowFile is made up of two components - content (data that is represented by FlowFile), attributes(characteristics about data, metadata)
- uuid - unique identifier for FlowFile
- filename - human-readable name used while storing FlowFiles
- path - complete heirarchy path to the location where FlowFile was stored












Please take this survey :)
https://goo.gl/forms/ZkAV9dZLshT5jfrN2
